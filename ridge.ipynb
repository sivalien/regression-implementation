{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для Ridge обозначения сохраняются, но функция потерь меняется: \n",
    "   \n",
    "$Q = ||\\mathbb{Y} - \\mathbb{X}\\omega||_2^2 + \\alpha||\\omega||_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем шаг градиентного спуска для L2-регуляризации аналогичным способом:  \n",
    "  \n",
    "  $dQ\\big|_{\\omega_{*}} = -2\\mathbb{X}^T<\\mathbb{Y} - \\mathbb{X}\\omega, \\omega_{*}> +  2\\alpha<w, \\omega_{*}> = 2<\\mathbb{X}^T(\\mathbb{X}\\omega - \\mathbb{Y}) + \\alpha\\omega, \\omega_{*}>$  \n",
    "    \n",
    "  $\\nabla_{\\omega}Q = 2(\\mathbb{X}^T(\\mathbb{X}\\omega - \\mathbb{Y}) + \\alpha\\omega)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class Ridge(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, alpha, batch_size=35, num_steps=500, lr=1e-2):\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        w = np.random.randn(X.shape[1])[:, None]\n",
    "        n_objects = len(X)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            sample_indices = np.random.randint(0, n_objects, size=self.batch_size)\n",
    "            w -= 2 * self.lr * ( np.dot(X[sample_indices].T, np.dot(X[sample_indices], w) - Y[sample_indices]) / self.batch_size + self.alpha * w)\n",
    "\n",
    "        self.w = w\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X@self.w"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
